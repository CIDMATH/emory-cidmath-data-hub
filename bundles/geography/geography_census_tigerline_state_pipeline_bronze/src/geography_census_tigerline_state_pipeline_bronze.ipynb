{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1609a532-e4aa-4c74-9611-5235e7daf1c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install geopandas\n",
    "%pip install shapely\n",
    "%pip install fiona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "795a8063-aa3b-4672-b98b-a2e02f944fb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## STEP 1: Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14c42018-4284-4fe5-a2ad-277f4d036e03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+h3_hint": "",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import dlt\n",
    "import zipfile\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "from dateutil.parser import isoparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e24310a-0ba7-4f50-a97d-8215b3451946",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## STEP 2: Read Data from Volume into Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb940b8-c667-4228-b071-2c4474ea8667",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n/root/.ipykernel/1225/command-6056201857388111-4202720210:18: UserWarning: Geometry column does not contain geometry.\n  gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "<html>\n",
       "  <style>\n",
       "<style>\n",
       "      html {\n",
       "        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,\n",
       "        Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,\n",
       "        Noto Color Emoji,FontAwesome;\n",
       "        font-size: 13;\n",
       "      }\n",
       "\n",
       "      .ansiout {\n",
       "        padding-bottom: 8px;\n",
       "      }\n",
       "\n",
       "      .createPipeline {\n",
       "        background-color: rgb(34, 114, 180);\n",
       "        color: white;\n",
       "        text-decoration: none;\n",
       "        padding: 4px 12px;\n",
       "        border-radius: 4px;\n",
       "        display: inline-block;\n",
       "      }\n",
       "\n",
       "      .createPipeline:hover {\n",
       "        background-color: #195487;\n",
       "      }\n",
       "\n",
       "      .tag {\n",
       "        border: none;\n",
       "        color: rgb(31, 39, 45);\n",
       "        padding: 2px 4px;\n",
       "        font-weight: 600;\n",
       "        background-color: rgba(93, 114, 131, 0.08);\n",
       "        border-radius: 4px;\n",
       "        margin-right: 0;\n",
       "        display: inline-block;\n",
       "        cursor: default;\n",
       "      }\n",
       "\n",
       "      table {\n",
       "        border-collapse: collapse;\n",
       "        font-size: 13px;\n",
       "      }\n",
       "\n",
       "      th {\n",
       "        text-align: left;\n",
       "        background-color: #F2F5F7;\n",
       "        padding-left: 8px;\n",
       "        padding-right: 8px;\n",
       "      }\n",
       "\n",
       "      tr {\n",
       "        border-bottom: solid;\n",
       "        border-bottom-color: #CDDAE5;\n",
       "        border-bottom-width: 1px;\n",
       "      }\n",
       "\n",
       "      td {\n",
       "        padding-left: 8px;\n",
       "        padding-right: 8px;\n",
       "      }\n",
       "\n",
       "      .dlt-label {\n",
       "        font-weight: bold;\n",
       "      }\n",
       "\n",
       "      ul {\n",
       "        list-style: circle;\n",
       "        padding-inline-start: 12px;\n",
       "      }\n",
       "\n",
       "      li {\n",
       "        padding-bottom: 4px;\n",
       "      }\n",
       "</style></style>\n",
       "  \n",
       "<div class=\"ansiout\">\n",
       "<span class='tag'>bronze_census_tigerline_state</span> is defined as a\n",
       "<span class=\"dlt-label\">Delta Live Tables</span> dataset\n",
       " with schema: \n",
       "</div>\n",
       "\n",
       "  \n",
       "<div class=\"ansiout\">\n",
       "   <table>\n",
       "     <tbody>\n",
       "       <tr>\n",
       "         <th>Name</th>\n",
       "         <th>Type</th>\n",
       "       </tr>\n",
       "       \n",
       "<tr>\n",
       "   <td>REGION</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>DIVISION</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>STATEFP</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>STATENS</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>GEOID</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>STUSPS</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>NAME</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>LSAD</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>MTFCC</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>FUNCSTAT</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>ALAND</td>\n",
       "   <td>bigint</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>AWATER</td>\n",
       "   <td>bigint</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>INTPTLAT</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>INTPTLON</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>geometry</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>zip_filename</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>GEOIDFQ</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "     </tbody>\n",
       "   </table>\n",
       "</div>\n",
       "\n",
       "  <div class =\"ansiout\">\n",
       "    To populate your table you must either:\n",
       "    <ul>\n",
       "      <li>\n",
       "        Run an existing pipeline using the\n",
       "        <span class=\"dlt-label\">Delta Live Tables</span> menu\n",
       "      </li>\n",
       "      <li>\n",
       "        Create a new pipeline: <a class='createPipeline' href=\"?o=4097717366064038#joblist/pipelines/create?initialSource=%2FUsers%2Fconnor.vanmeter%40emory.edu%2FUntitled%20Notebook%202025-06-23%2012%3A41%3A19&redirectNotebookId=1730625543799089\">Create Pipeline</a>\n",
       "      </li>\n",
       "    </ul>\n",
       "  <div>\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Spark session\n",
    "spark = SparkSession.getActiveSession()\n",
    "\n",
    "# Volume path\n",
    "zip_dir = \"/Volumes/emory_cidmath_data_hub/geography/census_tigerline/state\"\n",
    "\n",
    "# Get all entries that are directories and look like ISO 8601 timestamps\n",
    "timestamp_dirs = [\n",
    "    d for d in os.listdir(zip_dir)\n",
    "    if os.path.isdir(os.path.join(zip_dir, d))\n",
    "    and d[:4].isdigit()\n",
    "]\n",
    "\n",
    "# Parse the timestamp strings into datetime objects\n",
    "parsed_dirs = [(d, isoparse(d)) for d in timestamp_dirs]\n",
    "\n",
    "# Find the directory with the max datetime\n",
    "latest_dir = max(parsed_dirs, key=lambda x: x[1])[0]\n",
    "\n",
    "# Full path to the latest directory\n",
    "latest_dir_path = os.path.join(zip_dir, latest_dir)\n",
    "\n",
    "# Temporary local extraction path\n",
    "extract_root = os.path.join(latest_dir_path, \"shapefiles\")\n",
    "os.makedirs(extract_root, exist_ok=True)\n",
    "\n",
    "# Helper: extract shapefile and read with geopandas\n",
    "def read_shapefile_from_zip(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_root)\n",
    "        shp_file = [f for f in zip_ref.namelist() if f.endswith(\".shp\")][0]\n",
    "        gdf = gpd.read_file(os.path.join(extract_root, shp_file))\n",
    "        gdf[\"geometry\"] = gdf[\"geometry\"].apply(lambda geom: geom.wkt)  # convert for Spark\n",
    "        return pd.DataFrame(gdf)\n",
    "\n",
    "# Union of all GeoPandas DataFrames\n",
    "all_dfs = []\n",
    "for zip_file in os.listdir(latest_dir_path):\n",
    "    if zip_file.endswith(\".zip\"):\n",
    "        zip_path = os.path.join(latest_dir_path, zip_file)\n",
    "        try:\n",
    "            pdf = read_shapefile_from_zip(zip_path)\n",
    "            if zip_file == 'tl_2000_us_state.zip':\n",
    "                rename_map = {col: col.replace(\"00\", \"\") for col in pdf.columns if col.endswith(\"00\")}\n",
    "                pdf.rename(columns=rename_map, inplace=True)\n",
    "            elif zip_file == 'tl_2010_us_state.zip':\n",
    "                rename_map = {col: col.replace(\"10\", \"\") for col in pdf.columns if col.endswith(\"10\")}\n",
    "                pdf.rename(columns=rename_map, inplace=True) \n",
    "            pdf[\"zip_filename\"] = zip_file\n",
    "            all_dfs.append(pdf)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to process {zip_file}: {e}\")\n",
    "\n",
    "# Combine and convert to Spark\n",
    "if all_dfs:\n",
    "    combined_pdf = pd.concat(all_dfs, ignore_index=True)\n",
    "    df_spark = spark.createDataFrame(combined_pdf)\n",
    "else:\n",
    "    df_spark = spark.createDataFrame([], schema=\"GEOID STRING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33b87c52-5ed8-4427-bfe0-dafde960b441",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## STEP 3: Write Delta Live Table Materialized View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a1c4fc9-562f-443b-b007-f985495fa484",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "  name=\"bronze_census_tigerline_state\",\n",
    "  comment=\"Raw ingestion of Census TigerLine state geography data\"\n",
    ")\n",
    "def bronze_census_tigerline_state():\n",
    "  return (\n",
    "    df_spark\n",
    "    .drop('GEOIDFQ')\n",
    "    .orderBy([\"zip_filename\", \"GEOID\"], ascending=[True, True])\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_census_tigerline_state",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}